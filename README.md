Project Proposal: Audio Signal Processing and Instrument Recognition
Objective

The project aims to design a reproducible pipeline for musical instrument recognition. Using audio signal processing techniques, it focuses on flute, guitar, and vocal samples from the NSynth dataset, exploring how preprocessing and feature representations affect classification performance.

Background

Audio signals are non-stationary and require short-time analysis for effective representation. Classical signal processing methods such as pre-emphasis, framing, and windowing, followed by Fourier-based techniques, provide the foundation for extracting meaningful features. This project builds on these techniques to demonstrate their effectiveness in real-world audio classification tasks.

Methodology

Dataset Preparation – Select flute, guitar, and vocal samples from the NSynth dataset, with resampling for uniformity.

Preprocessing – Apply pre-emphasis filtering, framing, and windowing.

Time-Frequency Analysis – Use FFT and STFT to illustrate trade-offs in temporal and frequency resolution.

Feature Extraction – Compute Zero-Crossing Rate, Energy, Entropy, MFCCs, and harmonic features.

Classification – Train an ECOC-SVM model to recognize instrument classes, with evaluation via accuracy and confusion matrix.

Data Augmentation (FM Synthesis) – Generate woodwind-like signals to enrich the dataset and explore robustness improvements.

Expected Outcomes

A functional pipeline demonstrating the connection between signal processing stages and classification outcomes.

Instrument recognition accuracy of ~80% with SVM, validated on flute, guitar, and vocal classes.

Visualization of features (t-SNE, spectrograms) that highlight separability between instrument categories.

Future Work

Extend dataset to more instrument categories and balance sample sizes.

Explore CNN-based models on spectrograms for improved classification accuracy.

Develop a real-time recognition demo (MATLAB App Designer or Python GUI).

Investigate adversarial training and augmentation strategies using synthesized signals.
